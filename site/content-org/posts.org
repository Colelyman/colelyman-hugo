#+TITLE: posts
#+HUGO_BASE_DIR: ../
#+HUGO_SECTION: post
#+SEQ_TODO: TODO DRAFT DONE
#+PROPERTY: header-args :eval never-export

#+OPTIONS: creator:t toc:nil

* Blog Ideas
** DONE Colored de Bruijn Graphs :BIOINFORMATICS:
CLOSED: [2018-07-11 Wed 13:47]
:PROPERTIES:
  :EXPORT_FILE_NAME: colored-de-bruijn-graphs
:END:
I have really wanted to write this post for a long time, but seem to only now
get around to it. For more than a year now my research in the
[[http://bioresearch.byu.edu/][Computational Sciences Lab (CSL)]] at [[https://byu.edu][Brigham Young University (BYU)]] we have been
researching various applications of the Colored de Bruijn Graph (CdBG). It all
started when we explored some novel phylogenetic reconstruction methods in the
CS 601R class during Winter semester 2017. We (or at least, I) kept being drawn
back to CdBG's and their potential for phylogeny reconstruction. Here are some
of the things that I have learned along the way!
*** Related Work
As with most scientific endeavors, this project certainly stands on the
shoulders of giants. Some of these giants include the following papers and their
respective authors. I think that they have done amazing work and I admire their
methods.
  - [[http://dx.doi.org/10.1038/ng.1028][De novo assembly and genotyping of variants using colored de Bruijn graphs]]
    :: Zamin Iqbal et al.'s original paper introducing the CdBG's application to
    Bioinformatics. Even though their implementation isn't very efficient, it
    established the usefulness of the data structure in the Bioinformatic
    community.
  - [[http://dx.doi.org/10.1093/bioinformatics/btw609][TwoPaCo: an efficient algorithm to build the compacted de Bruijn graph from
    many complete genomes]] :: Ilia Minkin et al.'s work on discovering bubbles
    within the CdBG structure, which influenced our thinking and guided our
    work.
  - [[http://dx.doi.org/10.1186/s12864-015-1647-5][An assembly and alignment-free method of phylogeny reconstruction from
    next-generation sequencing data]] :: Huan Fan et al.'s application of a
    fantastic distance based phylogenetic tree reconstruction algorithm that I
    have found to be very accurate (and talk about fast). I love the simplicity
    of their model of evolution (based on the [[https://en.wikipedia.org/wiki/Jaccard_index][Jaccard Index]]), I find that it is
    very elegant.
*** Motivation
We want to use the CdBG to reconstruct phylogenetic trees because it is very
efficient computationally. The CdBG can be constructed in \(O(n)\) time and space
and it can utilize whole genome sequences, which is a shortcoming of many of the
traditional phylogenetic tree reconstruction algorithms.

Furthermore, we also figured that the CdBG contains more information than many
of the kmer counting methods, and if they can perform so well then the CdBG will
only be able to perform better because it not only stored the kmers (as nodes in
the graph), but it also stores the context in which those kmers occur (as edges
where \(k - 1\) basepairs overlap on either end of the kmer).
*** Our Contribution
**** =kleuren=
In order to prove our hypothesis, we did what every self-respecting Computer
Scientist would do, we wrote a program to figure out if it worked. We call our
program [[https://github.com/Colelyman/kleuren][=kleuren=]], which is Dutch for "colors" (referring to the colors in the
CdBG).

=kleuren= works by finding /bubble/ regions of the CdBG. A bubble is defined as
a subgraph of the CdBG that consists of a start and end node that are present in
$n$ or more colors, and there are multiple paths connecting the start node to
the end node; where $n$ is a given parameter and is no greater than the total
number of colors in the CdBG and a path is simply a traversal from one node to
another.

After the bubbles are found, they are aligned through Multiple Sequence
Alignment (MSA) via [[https://mafft.cbrc.jp/alignment/software/][MAFFT]] and then each MSA block is concatenated to form a
supermatrix. The supermatrix is then fed into a Maximum-Likelihood program
([[http://www.iqtree.org/][IQ-TREE]]) to reconstruct the phylogenetic tree of the taxa.
**** How Bubbles are Found
=kleuren= uses fairly simple and straightforward algorithms to find
the bubbles, which is broken up into two steps: Finding the End Node
and Extending the Paths.
***** Finding the End Node
=kleuren= iterates over the super-set (the union of all kmers from all
taxa) as potential start nodes (in a dBG the nodes are kmers, thus
$node == kmer$). Given a kmer, it is queried in the CdBG and the number
of taxa (or colors, thus $taxon == color$) is calculated to determine if
the number of colors for that kmer, $c$, is greater than or equal to $n$,
where $n$ is a parameter provided by the user.

If $c \geq n$ then the node is a valid start node and a breadth-first
search is performed starting from this node until another node is
found where the number of colors that it contains is greater than or
equal to $n$, which then becomes the end node.
***** Extending the Paths
After an end node is discovered, the sequence of each path between the
start and end nodes must be calculated. In order to discover a path in
a dBG, one must /collapse/ edges by appending the last nucleotide of
the next node to the previous node's sequence. For example, if a node
is =ACT -> CTG=, then the collapsed sequence will turn out to be
=ACTG=.

This is implemented as at most $c$ depth-first searches, where $c$ is
the number of colors. The number of depth-first searches decreases as
the number of paths with shared colors increases.
*** Further Reading
If you are interested in the details of our algorithm and would like to see some
results, please check out our paper [[https://ieeexplore.ieee.org/document/8251300/][Whole Genome Phylogenetic Tree
Reconstruction Using Colored de Bruijn Graphs]] ([[https://arxiv.org/abs/1709.00164][preprint]]). We are currently
working on extending =kleuren= to improve its efficiency.
** DONE Intelligence to Arrogance Ratio
CLOSED: [2018-08-18 Sat 11:57]
:PROPERTIES:
  :EXPORT_FILE_NAME: intelligence-to-arrogance-ratio
:END:
Yesterday I graduated with my Bachelor's degree from [[https://byu.edu][Brigham Young University]]
and attended the Convocation services for my college (College of Physical and
Mathematical Sciences). Our dean, [[https://madison.byu.edu/][Dr. Shane Reese]], gave a very inspirational
talk, of which I would like to share part of it with you.

Dr. Reese's talk centered on two pieces of advice to the graduates, working hard
and being meek. He also provided tools of measurement in order for us to see how
well we are following his advice.

His first piece of advice was to work really hard. He shared that there is no
substitute to working hard, and that one can measure each day if one has given
an honest day's work.

The second piece of advice is what I would like to primarily focus on, and that
advice was to be meek. As a tool to measure one's meekness, he shared a
conversation that he had overheard where a faculty member was discussing the
president of our university, [[https://president.byu.edu/bio][Dr. Kevin J. Worthen]]. This faculty member described
Dr. Worthen as having an incredibly high intelligence to arrogance ratio,
illustrated below.

$\frac{intelligence}{arrogance}$

Imagine that one's intelligence and arrogance can be quantified, then the
intelligence to arrogance ratio would be your quantified intelligence divided by
your quantified arrogance. For example, if one is incredibly dumb but also quite
full of themselves, then the ratio would be extremely low. On the other hand, if
one is reasonably intelligent while still humble, then the ratio is quite high.
As a third example, if one is intelligent, but also pompous, then the ratio will
be around 1.

In my experience, the individuals with a low ratio are the most pleasant to be
around, because they offer interesting insights and advice while not being
condescending. They are the ones that show you (rather than tell you) how
intelligent they are.

I found this advice to be incredibly insightful and useful to all. I hope to
increase my own intelligence to arrogance ratio as I pursue higher education and
gain more life experience.
** TODO Hugo + Micropub = Bliss
:PROPERTIES:
  :EXPORT_FILE_NAME: hugo-micropub-bliss
:END:
This post is about how I managed to set up a micropub endpoint to publish to my
Hugo static site hosted on Netlify. Now that I have completed it, I can say that
it was quite the journey.

Here are some of the invaluable resources that I used along the way:
  - https://rhiaro.co.uk/2015/04/minimum-viable-micropub
  - https://quill.p3k.io/creating-a-micropub-endpoint
  - https://tokens.indieauth.com/token
  - https://www.netlify.com/docs/functions/
  - https://www.w3.org/TR/micropub/
  - https://github.com/google/go-github
  - https://github.com/google/go-github/blob/master/example/commitpr/main.go
** TODO Multi-Editing Like a Boss (with Emacs)
:PROPERTIES:
  :EXPORT_FILE_NAME: multi-editing-like-a-boss--with-emacs
:END:
Reference the following post https://sam217pa.github.io/2016/09/11/nuclear-power-editing-via-ivy-and-ag/
** DONE Modelling Gravity using the Euler Method in Haskell
CLOSED: [2018-09-05 Wed 22:54]
:PROPERTIES:
  :EXPORT_FILE_NAME: euler-s-method-in-haskell
:END:
*** Introduction
In my predictive modelling class, we were given a homework assignment to apply
the [[https://en.wikipedia.org/wiki/Euler_method][Euler method]] for a simple equation and then write a program to
compute the method. I will show what I did to apply the Euler method, and then
how I programmed it using Haskell.
*** Our Equation
For our task we were given the simple equation to run the Euler method on:

\begin{equation}
\frac{dv}{dt} = -g
\end{equation}

where $g=9.8 m/s^2$ (this should look familiar to any physicists). This equation
models the falling of an object (on Earth).
*** Applying the Euler Method
To apply the Euler method, one must first have a base case. In this instance,
assume that the initial velocity of the object is 0, thus when $t = 0$, $v = 0$;
in other words $v(0) = 0$.

Now, from my understanding the Euler method is basically a recursive way to
approximate the function. Thus, let $h$ be a given step size and $v(t)$ be the
velocity at a given time $t$, and $v_n$ be the velocity at a given step $n$. It
follows by Euler's method that:

\begin{equation}
v_{n+1} = v_n + hv(t)
\end{equation}

In English, this equation is saying that the velocity at the next time step is
equal to the velocity at the previous time step ($v_n$) plus the velocity of the
current time ($v(t)$) times the step size ($h$). How do you compute the velocity
at the previous time step ($v_n$)? Well, it is $v_n = v(t - h)$, the velocity at
the previous time step.
*** Translating Math into Haskell
Due to Haskell's nature, it isn't hard to translate mathematical equations into
Haskell functions (if you have ever seen a Haskell function, you know what I
mean). Because of the recursive nature, the reasoning behind the Haskell
function is a little bit different than the mathematical intuition presented
earlier, but it is the same principle.

First, let's define $g$ in Haskell:
#+BEGIN_SRC haskell :export code
g :: Float
g = 9.8
#+END_SRC
This is pretty straightforward, as defined earlier $g = 9.8$ (the acceleration
of gravity on Earth). If you are unfamiliar with Haskell, the first line
describes the type of $g$ and the second line sets the value of $g$. Now let's
move onto the meat of the algorithm!

Forming the function step by step, the first step is to establish the types that
our function will be dealing with:
#+BEGIN_SRC haskell :export code
v :: Float -> Float -> Float
#+END_SRC
Which means that our function =v= will take two parameters (that are of type
=Float=), and return a value that is a =Float=.

Next, let's create our function modelled after the formulae we presented
earlier:
#+BEGIN_SRC haskell :export code
v :: Float -> Float -> Float
v t h = v_n + v_t
    where v_n = v (t - h) h
          v_t = h * (-g)
#+END_SRC
this should look very similar to the equation above. However, the acute observer
will notice that this function is not complete because there is no base case for
the recursion to break, thus this function will run forever!!

At the beginning we assumed that our base case was that the initial velocity was
0, thus adding this to our function we get:
#+BEGIN_SRC haskell :export code
v :: Float -> Float -> Float
v t h | t > 0 = v_n + v_t
      | othwerwise = 0.0
    where v_n = v (t - h) h
          v_t = h * (-g)
#+END_SRC
In Haskell the =|= are called [[https://wiki.haskell.org/Pattern_guard][guards]], which essentially translates into a
conditional statement where the first expression that evaluates to true on the
left hand side of the === returns what is on the right hand side of the ===.

For example, if we test our function where $t = 1$ and $h = 1$, then the first
time the function is called the first guard will evaluate to true (because $t =
1; 1 > 0 = = True$) thus the function is called again (inside =v_n=), but $t =
0$ so the second guard is reached. Ultimately the function will return $9.8$.
*** Conclusion
This was my first encounter using the Euler method to do numerical analysis and
model an equation. I hope that you found this interesting and that you enjoy the
elegance of Haskell as much as I do!
** DONE Hamming Distance One-liner in Python
CLOSED: [2018-09-19 Wed 08:29]
:PROPERTIES:
  :EXPORT_FILE_NAME: hamming-distance-one-liner-in-python
:END:
The hamming distance of strings $a$ and $b$ is defined as the number of
character mismatches between $a$ and $b$. The hamming distance can be calculated
in a fairly concise single line using Python.

*** The Code
#+BEGIN_SRC python :exports code
def hamming(a, b):
    return len([i for i in filter(lambda x: x[0] != x[1], zip(a, b))])
#+END_SRC
*** The Explanation
If you aren't familiar with many of the shortcuts that Python provides, this
line may seem quite cryptic. To best explain how this function works, I will
expand it to the equivalent multi-line version, and then go over each part of
the multi-line version.
#+BEGIN_SRC python :exports code
def hamming(a, b):
    zipped_strings = zip(a, b)

    mismatched_chars = []

    # equivalent of the [...]
    for i in zipped_strings:
        # equivalent of the filter(lambda x: x[0] != x[1], ...)
        if i[0] != i[1]:
            mismatched_chars.append(i)

    return len(mismatched_chars)
#+END_SRC
**** Zip
=zip= is a useful built-in Python function that takes two lists as its arguments
and returns a list where each element is a tuple, and the first element in the
tuple comes from the first list and the second element in the tuple comes from
the second list. For example:
#+BEGIN_SRC python :exports both :results output
a = [1, 2, 3]
b = ['a', 'b', 'c']

print(list(zip(a, b)))
#+END_SRC

#+RESULTS:
: [(1, 'a'), (2, 'b'), (3, 'c')]

In this case, the elements of =a= are /paired up/ with the elements of =b=.
**** List comprehension
List comprehensions in Python are a very handy trick to shorten any =for= loop
in Python. They follow the form of =[... for i in iterable]= where the =...= is
replaced by the code that is run on each element of =iterable= (list, generator,
etc.).

An example of a list comprehension is:
#+BEGIN_SRC python :results output
evens = [i * 2 for i in range(10) if i % 2 == 0]

print(evens)
#+END_SRC

#+RESULTS:
: [0, 4, 8, 12, 16]

This code creates a list of all even numbers between 0 and 10, each of which are
multiplied by 2. Notice how the conditional is placed at the end of the expression.
**** Lambda functions
Lambda functions may look scary (mostly because it can be hard to recognize
where the parameters come from), but just think of them as functions that don't
have a name. Lambda functions are usually short functions that
perform something straight-forward. In the case of the one-liner, the lambda
function
#+BEGIN_SRC python :exports code
lambda x: x[0] != x[1]
#+END_SRC
takes one argument =x= (which is of type tuple) and checks if the two elements
of the tuple (=x[0]= and =x[1=) are equal, thereby returning a boolean value.
**** Filter
The final piece to our one-line puzzle, =filter=. In functional programming
there are patterns and ways to perform certain operations. Three ubiquitous
functions in any language resembling a functional language are =map=, =reduce=,
and =filter=. They are of themselves very simple, yet extremely powerful (if you
want to read more about how to use them in Python, I would recommend [[http://book.pythontips.com/en/latest/map_filter.html][Python
Tips]]).

=filter= takes two arguments, first a function that takes an element of an
iterable as input and returns a boolean, and second an iterable. In our one line
case, we have
#+BEGIN_SRC python :exports code
filter(lambda x: x[0] != x[1], zip(a, b))
#+END_SRC
As described earlier, =lambda= is just a function without a name, and zip is a
list of tuples from two elements of a list. Our =filter= expression returns a
list where the condition =x[0] != x[1]= is =True=, thus giving us a list of
characters that don't match up with one another. When we take the length of this
list we get, by definition, the hamming distance.
** DONE "The Art of computer programming"
CLOSED: [2018-11-10 Sat 11:08]
:PROPERTIES:
  :EXPORT_FILE_NAME: the-art-of-computer-programming
:END:
The title of Donald Knuth's famed series [[https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming][The Art of Computer Programming]] is
often misunderstood, and as he describes in his talk [[https://dl.acm.org/citation.cfm?id=361612][Computer programming as an
art]] which he delivered when he received the 1974 Turing award. I love this talk!
I think that it offers a unique perspective on programming that can be very
beneficial.

Knuth starts his talk with an explanation of the difference between an art and a
science through an etymologic analysis of the words. This seems to explain why
the fields of medicine have historically been considered arts even though our
modern perspective would consider them as sciences.

I can resonate with Knuth's observation:
#+BEGIN_QUOTE
My feeling is that when we prepare a program, it can be like composing poetry or
music; as Andrei Ershov has said, programming can give us both intellectual and
emotional satisfaction, because it is a real achievement to master complexity
and to establish a system of consist rules.
#+END_QUOTE

I believe that code can certainly be beautiful and the process of reducing a
problem down into a set of explicit rules can be extremely satisfying (although
at times, very frustrating). Many people consider programs to merely be a
computational recipe that executes commands at the will of the programmer.
However, I resonate much more with the idea of programming as "procedural
epistomology," (from [[https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-4.html#%25_toc_start][Structure and Interpretation of Computer Programs]]) meaning
that we construct programs to discover truth and use programs as a tool to
justify our knowledge.

I do have a hard time reconciling this idea of programming as "procedural
epistomology," essentially idealistic programming for discovering truth, and
pragmatic programming, programming to solve a problem. However, I think Knuth
addresses this in his talk quite nicely when he states that "we shouldn't feel
guilty about programs that are just for fun."

I enjoy how Knuth addresses the inverse relationship between amount of resources
and enjoyment of programming. The more constrained the resources in which we
work under, the more we tend to enjoy the programs we write. I like the idea of
working under contrived constraints as an exercise to increase our programming
abilities. I have never done this, but I sure would like to try it sometime!

In case you haven't read the talk, I would highly recommend it. I wonder if
there is a video recording of him delivering it, I'm sure that it would be a
pleasure to watch Knuth himself deliver it.

* Footnotes
* COMMENT Local Variables                          :ARCHIVE:
# Local Variables:
# eval: (add-hook 'after-save-hook #'org-hugo-export-wim-to-md-after-save :append :local)
# End:
